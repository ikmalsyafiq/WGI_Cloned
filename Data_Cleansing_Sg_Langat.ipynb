{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "pd.set_option('display.max_columns', None)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import math\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capacity Grouping & WTP Attribute Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Info about the WTP Capacity and water source\n",
    "wtpc = pd.read_csv('Design Capacity WTP.csv')\n",
    "wlb = ['small','medium','large']\n",
    "breaks = [0,20,200,np.inf]\n",
    "wtpc['ng'] = pd.cut(x=wtpc['Design Capacity (MLD)'], bins=breaks,labels=wlb)\n",
    "wtpc['nng'] = pd.cut(x=wtpc['Design Capacity (MLD)'], bins=breaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Data Loading & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Water Quality (WQ) Related Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'WQ\\Refined'\n",
    "db_dir = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "## Joining all csv file within the folder\n",
    "for i in db_dir:\n",
    "    df = pd.read_csv(i, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "fdb = pd.concat(li, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop unwanted column and fill na with big number 9999, then it will be removed when there is a change in data \n",
    "fdb = fdb.drop(['Unnamed: 0'],axis=1)\n",
    "fdb['Date'] = pd.to_datetime(fdb['Date'])\n",
    "cl = fdb.loc[:, fdb.dtypes == object].columns.to_list()\n",
    "cl.remove('wtp')\n",
    "for i in cl:\n",
    "    fdb[i] = fdb[i].fillna(9999)\n",
    "    fdb[i] = fdb[i].apply(lambda x: str(x).replace(',',''))\n",
    "fdb[cl] = fdb[cl].apply(pd.to_numeric)\n",
    "db = fdb.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get all the relevant columns (Daily average for further processing)\n",
    "avg = fdb.columns\n",
    "l = ['Quarter','wtp','Month','Date']\n",
    "avg = [x for x in avg if \"avg\" in x ] + l\n",
    "db['Month'] = db['Date'].dt.month\n",
    "db['Quarter'] = db['Date'].dt.quarter\n",
    "dc = db[avg].copy()\n",
    "\n",
    "## Drop due to data limitation (Only limited number of WTP do it on daily basis)\n",
    "dc= dc.drop(['Aluminium_avg', 'Fluoride_avg'],axis=1)\n",
    "avc = [x for x in dc.columns if \"avg\" in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = pd.merge(dc,wtpc[['wtp','Water Source','Lembangan']],on='wtp',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final Clean data for further processing\n",
    "dc = dc[(dc['Lembangan']=='Sg Langat') & (dc['Water Source']=='River')].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chemical Dosage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semenyih DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Semenyih is different due to data was extracted seperately by production team\n",
    "ec = [\"Alum Coagulant Sg Semenyih.xlsx\",\"Post Chlorine Sg Semenyih.xlsx\"]\n",
    "nc = [\"Fluoride Sg Semenyih.xlsx\",\"Lime Sg Semenyih.xlsx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcleans(x,ec,nc):\n",
    "    \n",
    "    ## Data Cleaning\n",
    "    dir = f\"CC\\sg_symh\\{x}\"\n",
    "    db1 = pd.read_excel(dir)\n",
    "    renc1 = {\"Date (dd/mm/yyyy)\":\"Date\"}\n",
    "    db1 = db1.rename(columns=renc1)\n",
    "    name = x.replace(\" Sg Semenyih.xlsx\",\"\")\n",
    "    db1 = db1[~db1[\"Date\"].isnull()].copy()\n",
    "    db1.drop(db1.tail(1).index,inplace=True)\n",
    "    db1 = db1.reset_index(drop=True)\n",
    "    db1[\"Date\"] = pd.to_datetime(db1[\"Date\"])\n",
    "    \n",
    "    ## Normal Page\n",
    "    if x in nc:\n",
    "        db1 = db1.rename(columns={\"Unnamed: 3\":f\"{name}\"})\n",
    "        fdb = db1[[\"Date\",f\"{name}\"]].copy()\n",
    "\n",
    "    ## Multiple Page\n",
    "    else:\n",
    "        db1 = db1.rename(columns={\"Unnamed: 9\":f\"{name}\"})\n",
    "        fdb = db1[[\"Date\",f\"{name}\"]].copy()\n",
    "    \n",
    "    return fdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "namely = ec + nc\n",
    "k = 0\n",
    "smdb = pd.DataFrame()\n",
    "for i in namely:\n",
    "    jdb = dcleans(i,ec,nc)\n",
    "    if k==0:\n",
    "        smdb = smdb.append(jdb)\n",
    "    else:\n",
    "        smdb = pd.merge(smdb,jdb,on=['Date'],how=\"left\")\n",
    "    k = k+1\n",
    "smdb['wtp'] = \"Sungai Semenyih\"\n",
    "redict = {\"Alum Coagulant\":\"Coagulant\",\"Post Chlorine\":\"Disinfectant\",\"Fluoride\":\"Flouridation\",\"Lime\":\"pH Adjuster\"}\n",
    "smdb = smdb.rename(columns=redict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "smdb1 = smdb[(smdb['Date']>=pd.to_datetime(\"1/1/2021\"))&(smdb['Date']<=pd.to_datetime(\"30/11/2021\"))].copy()\n",
    "smdb1 = smdb1.dropna()\n",
    "smdb1 = smdb1.reset_index(drop=True)\n",
    "smdb1['Month'] = smdb1['Date'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Chemical DB (Other WTP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'CC\\Chm_DB'\n",
    "dcb_dir = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "mm = []\n",
    "\n",
    "for i in dcb_dir:\n",
    "    dbo = pd.read_csv(i, index_col=None, header=0)\n",
    "    mm.append(dbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdb = pd.concat(mm, ignore_index=True)\n",
    "chdb = chdb.drop(['Unnamed: 0'],axis=1)\n",
    "chdb = chdb[chdb['Date']!='MONTHLY'].reset_index(drop=True)\n",
    "chdb['Date'] = chdb['Date'] + '-2021'\n",
    "chdb['Date'] = pd.to_datetime(chdb['Date'])\n",
    "chdb['Month'] = chdb['Date'].dt.month\n",
    "chdb['Quarter'] = chdb['Date'].dt.quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC = chdb.columns\n",
    "fFC = [x for x in FC if \"avg\" in x]\n",
    "rcol = ['wtp','Date','Month','Quarter']\n",
    "xxdb = chdb[fFC+rcol].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = [x for x in FC if \"avg\" in x]\n",
    "new = [x.replace(\" _avg\",\"\") for x in new]\n",
    "new = [x.replace(\"_avg\",\"\") for x in new]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regrouping Chemical Product to it's own purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdic = dict(zip(fFC,new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxdb = xxdb.rename(columns=xdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxdb = pd.merge(xxdb,wtpc[['wtp','Water Source','Lembangan']],on='wtp',how='left')\n",
    "x1db = xxdb[(xxdb['Lembangan']=='Sg Langat') & (xxdb['Water Source']=='River')].copy()\n",
    "x1db = x1db[x1db['wtp']!='Sungai Semenyih'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "avc2 = x1db.drop(['wtp', 'Date', 'Month','Quarter', 'Water Source', 'Lembangan'],axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "appl = x1db.groupby(['wtp']).mean().reset_index()\n",
    "wtpn = appl.wtp.unique()\n",
    "number = dict({'wtp':[],'Chem':[]})\n",
    "for i in wtpn:\n",
    "    number['wtp'].append(i)\n",
    "    jde = appl[appl['wtp']==i].drop(['wtp'],axis=1)\n",
    "    jde = jde.dropna(axis=1).columns\n",
    "    number['Chem'].append(jde)\n",
    "cgr = pd.read_csv(\"C.Grouping.csv\")\n",
    "Chdict = dict(zip(cgr['Chemical Name'].values,cgr['Correct Grouping']))\n",
    "df22=pd.DataFrame(number)\n",
    "df22=df22.assign(Chem=df22.Chem.map(','.join))\n",
    "df22=df22.set_index(['wtp']).apply(lambda x: x.str.split(',').explode()).reset_index()\n",
    "df22['Purpose']=df22['Chem'].apply(lambda x: Chdict.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop irrelevant rows\n",
    "df22 = df22.drop(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tocho = df22[(df22['wtp']!=\"Sungai Semenyih\")]['Chem'].unique()\n",
    "swtp = ['Bukit Tampoi New','Sungai Langat']\n",
    "jam = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = df22['Chem'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regroup pre & post chemical products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_lis = [x for x in lis if \"Pre\" in x]\n",
    "pos_lis = [x for x in lis if \"Post\" in x]\n",
    "total_lis = pre_lis + pos_lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = ['Soda Ash (Pre)','Soda Ash (Post)']\n",
    "lc = ['Liquid Chlorine (Pre)','Liquid Chlorine (Post)']\n",
    "hl = ['Hydrated Lime (Pre)','Hydrated Lime (Post)','Hydrated Lime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1db[total_lis] = x1db[total_lis].fillna(0)\n",
    "x1db['Hydrated_Lime_T'] = x1db[hl].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [dict(zip(hl,['Hydrated_Lime_T' for i in range(len(hl))]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for dictionary in li:\n",
    "    for k, v in dictionary.items():\n",
    "        d[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df22['Chem'] = df22['Chem'].apply(lambda x: d.get(x,x))\n",
    "df22 = df22.drop_duplicates(subset=['wtp','Chem'])\n",
    "df22 = df22.drop_duplicates(subset=['wtp','Purpose'],keep='first')\n",
    "tt = x1db['wtp'].unique()\n",
    "\n",
    "## Remove Sg Semenyih because it was extracted separately\n",
    "trdf = df22[(df22['wtp']!=\"Sungai Semenyih\")].copy()\n",
    "\n",
    "## Rename the aggregated chemical products to it's own purpose\n",
    "Chdict['Hydrated_Lime_T'] = 'pH Adjuster'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "jam = pd.DataFrame()\n",
    "x10db = x1db.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9319"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onew = 0\n",
    "for i in tt:\n",
    "    \n",
    "    c2t = trdf[trdf['wtp']==i]['Chem'].unique()\n",
    "    c2t = np.append(c2t,np.array(['Date','wtp']))\n",
    "    op = x10db[x10db['wtp']==i][c2t].copy()\n",
    "    op = op.rename(columns=Chdict)\n",
    "    \n",
    "    if onew == 0:\n",
    "        jam = jam.append(op)\n",
    "    else:\n",
    "        jam = pd.concat([jam, op], ignore_index=False)\n",
    "    \n",
    "    onew = onew+1\n",
    "    \n",
    "    del c2t, op\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Mergeing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl2 = smdb1.loc[:, smdb1.dtypes == object].columns.to_list()\n",
    "cl2.remove('wtp')\n",
    "smdb1[cl2] = smdb1[cl2].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "wqdb1 = dc[['wtp', 'pH_avg', 'Date', 'Turbidity_avg', 'Color_avg',\n",
    "       'Iron_avg', 'Ammonia_avg', 'Manganese_avg']].copy()\n",
    "jam2 = pd.concat([jam, smdb1], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFDB = pd.merge(wqdb1,jam2,on=['wtp','Date'],how='left')\n",
    "FFDB = FFDB.sort_values(by=['wtp','Date'])\n",
    "\n",
    "### pH shouldn't be more thant 14, remove human error records\n",
    "FFDB = FFDB[FFDB['pH_avg']<=14].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_name = FFDB.drop(['wtp', 'Date','Month'],axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Engineering (Daily % Changes compared to median value)\n",
    "for i in the_name:\n",
    "    means = FFDB.groupby('wtp')[f'{i}'].transform('median')\n",
    "    FFDB[f'{i}_chim'] = FFDB[f'{i}'] - means\n",
    "    FFDB[f'{i}_chpctm'] = FFDB[f'{i}_chim']/means*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfi = [x for x in FFDB.columns if \"_chpctm\" in x]\n",
    "to_c4 = FFDB[tfi].copy()\n",
    "\n",
    "## Dropping Auxiliary & Polyelectrolyte because project does not focus study on these product (Low usage & only certain WTP using it)\n",
    "to_c4 = to_c4.drop(['Auxiliary Chemical_chpctm', 'Polyelectrolyte_chpctm'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General Columns for EDA\n",
    "ge = ['pH_avg','Turbidity_avg', 'Color_avg','Iron_avg', 'Ammonia_avg', 'Manganese_avg','Disinfectant','Coagulant', 'Flouridation','pH Adjuster']\n",
    "lib = list(to_c4.columns) + ['Date','wtp'] + ge\n",
    "to_c6 = FFDB[lib].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_c6.to_csv('C_data/WGIDB_SgLGTN_v2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0c4439b51d35f9272108bf59add1fd162c01386f5fe08b715fb4f15958d0f74e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
